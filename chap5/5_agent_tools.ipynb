{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomli, os\n",
    "with open(\"../.streamlit/secrets.toml\",\"rb\") as f:\n",
    "    secrets = tomli.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"OPENAI_API_KEY\"]\n",
    "os.environ[\"SERPAPI_API_KEY\"] = secrets[\"SERPAPI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smith: Simple mini independent tool handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'smith' from 'c:\\\\Users\\\\ydebray\\\\Downloads\\\\gpt-programming-book\\\\chap5\\\\smith.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "smith = importlib.import_module('smith')\n",
    "importlib.reload(smith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smith import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of September 2021, the CEO of Twitter is Jack Dorsey.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Who is the CEO of Twitter?'\n",
    "print(agent(prompt)) # Calling agent without passing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search',\n",
       "  'desc': 'Useful for when you need to answer questions about current events.',\n",
       "  'example': 'What movie won best picture in 2023?'},\n",
       " {'name': 'python',\n",
       "  'desc': 'Useful for when performing computing and trying to solve mathematical problems',\n",
       "  'example': 'What is the 10th element of the Fibonacci suite'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = load_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool: search\n",
      "------------------\n",
      "The CEO of Twitter is Linda Yaccarino, as reported by The Verge.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Who is the CEO of Twitter?'\n",
    "res = agent(prompt,tools=tools)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking down the tool choice and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'What movie won best picture in 2024?'\n",
    "pick_tool(prompt,tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the user request given the following information retrieved from an internet search:\n",
      "  Oppenheimer\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "res = search_tool(prompt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool: python\n",
      "------------------\n",
      "import math\n",
      "\n",
      "result = math.sqrt(42)\n",
      "print(result)\n"
     ]
    }
   ],
   "source": [
    "prompt = 'What is the square root of 42?'\n",
    "# res = pick_tool(prompt,tools)\n",
    "res = agent(prompt,tools=tools)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should search for the current CEO of Twitter.\n",
      "Action: Search\n",
      "Action Input: \"current CEO of Twitter\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLinda Yaccarino\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThat doesn't seem right, I should search again.\n",
      "Action: Search\n",
      "Action Input: \"current CEO of Twitter 2021\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mParag Agrawal\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mParag Agrawal is the current CEO of Twitter.\n",
      "Final Answer: Parag Agrawal\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Parag Agrawal'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Load the model\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "# Load in some tools to use\n",
    "tools = load_tools([\"serpapi\"])\n",
    "# Finally, let's initialize an agent with:\n",
    "# 1. The tools\n",
    "# 2. The language model\n",
    "# 3. The type of agent we want to use.\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "# Now let's test it out!\n",
    "agent.run(\"who is the ceo of twitter?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the agent is getting the date wrong.\n",
    "Let's create our own tool to handle the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool that returns the current date\n",
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ydebray\\Downloads\\gpt-programming-book\\env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should use the `time` tool to find out today's date.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m2024-05-04\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 2024-05-04\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Let's first find out today's date and then search for the current CEO of Twitter. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m2024-05-04\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that we have today's date, let's search for the current CEO of Twitter. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"current CEO of Twitter 2024\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLinda Yaccarino\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Linda Yaccarino\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'As of today, who is the CEO of twitter? (First get the date and then ask the question.)',\n",
       " 'output': 'Linda Yaccarino'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"who is the CEO of twitter today? (First get the date and then answer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another tool for search: DuckDuckGo\n",
    "\n",
    "`pip install duckduckgo_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Twitter framed a copy of one of her motivational tweets about \"wearing 4 inch heels\" while working as an executive and hung it in a dining common area in the San Francisco office. She has also ... FILE - Twitter CEO Elon Musk, center, speaks with Linda Yaccarino, chairman of global advertising and partnerships for NBC, at the POSSIBLE marketing conference, Tuesday, April 18, 2023, in Miami Beach, Fla. Musk announced Friday, May 12, 2023, that he\\'s hiring Yaccarino to be the new CEO of San Francisco-based Twitter, which is now called X Corp. (AP Photo/Rebecca Blackwell, File) Updated on: May 15, 2023 / 9:49 AM EDT / MoneyWatch. Elon Musk has tapped Linda Yaccarino, until this week the head of advertising at NBCUniversal, to replace him as CEO of Twitter, he announced ... David Becker/Getty Images. Jack Dorsey cofounded Twitter in 2006 and the company made him a billionaire. He stepped down as Twitter CEO in 2021 and supported Elon Musk\\'s takeover of the company ... Jack Dorsey is the cofounder of Twitter and Block (formerly Square), and was the CEO of both companies until 2021. He is also a philanthropist who has given away billions of dollars to various causes, and a self-made billionaire who dropped out of college twice.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ydebray\\Downloads\\gpt-programming-book\\env\\lib\\site-packages\\curl_cffi\\aio.py:204: UserWarning: Curlm alread closed! quitting from process_data\n",
      "  warnings.warn(\"Curlm alread closed! quitting from process_data\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()\n",
    "res = search.run(\"CEO of Twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [OpenAI Blog function calling](https://openai.com/blog/function-calling-and-other-api-updates)\n",
    "- [OpenAI Doc function calling](https://platform.openai.com/docs/guides/gpt/function-calling)\n",
    "- [How_to_call_functions_with_chat_models.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb)\n",
    "- [How_to_call_functions_for_knowledge_retrieval.ipynb](https://github.com/openai/openai-cookbook/blob/0d1436b8d9b858c220d708a446a09eef54be61b0/examples/How_to_call_functions_for_knowledge_retrieval.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomli, openai, json\n",
    "with open('../.streamlit/secrets.toml','rb') as f:\n",
    "    toml_dict = tomli.load(f)\n",
    "openai.api_key = toml_dict['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get_current_weather.json']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "functions_list = os.listdir(\"functions\")\n",
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_current_weather',\n",
       "  'description': 'Get the current weather in a given location',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'location': {'type': 'string',\n",
       "     'description': 'The city and state, e.g. San Francisco, CA'},\n",
       "    'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']}},\n",
       "   'required': ['location']}}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions = []\n",
    "with open(\"functions/get_current_weather.json\", \"r\") as f:\n",
    "    functions.append(json.loads(f.read()))\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather'),\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: send the conversation and available functions to GPT\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}]\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "dict(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"Boston, MA\", \"temperature\": \"72\", \"unit\": null, \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: check if GPT wanted to call a function, and call it\n",
    "if response_message.function_call is not None:\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }  # only one function in this example, but you can have multiple\n",
    "    function_name = response_message.function_call.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "function_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in Boston is sunny and windy with a temperature of 72 degrees.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: send the info on the function call and function response to GPT\n",
    "messages.append(response_message)  # extend conversation with assistant's reply\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": function_response,\n",
    "    }\n",
    ")  # extend conversation with function response\n",
    "second_response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    ")  # get a new response from GPT where it can see the function response\n",
    "second_response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
