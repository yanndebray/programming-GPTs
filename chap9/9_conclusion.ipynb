{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question answering on chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomli, os\n",
    "with open(\"../.streamlit/secrets.toml\",\"rb\") as f:\n",
    "    secrets = tomli.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = {\n",
    "       'chap1':'Chap 1 - Intro.pdf',\n",
    "       'chap2':'Chap 2 - The ChatGPT API.pdf',\n",
    "       'chap3':'Chap 3 - Chaining & Summarization.pdf',\n",
    "       'chap4':'Chap 4 - Vector search & Question Answering.pdf',\n",
    "       'chap5':'Chap 5 - Agents & Tools.pdf',\n",
    "       'chap6':'Chap 6 - Speech-to-Text & Text-to-Speech.pdf',\n",
    "       'chap7':'Chap 7 - Vision.pdf',\n",
    "       'chap8':'Chap 8 - DALL-E.pdf',\n",
    "       'chap9':'Chap 9 - Conclusion.pdf',\n",
    "       'chap10':'Chap 10 - Appendix.pdf'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, <_io.FileIO [closed]>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add all chapters into one big PDF\n",
    "from pypdf import PdfWriter\n",
    "pdfs = []\n",
    "for k,v in pdf.items():\n",
    "    if v:\n",
    "        pdfs.append(f'../{k}/{v}')\n",
    "merger = PdfWriter()\n",
    "for pdf in pdfs:\n",
    "    merger.append(pdf)\n",
    "merger.write('book.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('book.pdf')\n",
    "pages = loader.load_and_split()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(pages, embeddings,persist_directory=f\"./chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the vector databases mentioned in the book?',\n",
       " 'result': 'The vector databases mentioned in the book are Chroma, Pinecone, Weaviate, Faiss, Qdrant, and MongoDB.',\n",
       " 'source_documents': [Document(page_content='15 \\n Finally, after trying several vector databases, you can build a production system with Pinecone like this:  \\n \\nAs you will see in a future chapter, this application21 can be nicely architectured with plugins, that clearly \\ndefine the API with two main endpoints: upsert  (to update or insert the vector database), or query  that \\nwill convert the prompt into an embedding and perform a vector search to find the N (= 5) closest ones.  \\n4.3. Application: Question answering on Book  \\nThis is what the app will look like, a simple text entry and a button to trigger the workflow. The answer \\nwill be written in the body, with sources from the document corpus. Check out the code under \\nchap4/qa_app.py  \\n \\n \\n21 https://github.com/pinecone -io/examples/blob/master/learn/generation/openai/chatgpt/plugins/langchain -\\ndocs -plugin.ipynb  ChatGPT Plugins: Build Your Own in Python! https://www.youtube.com/watch?v=hpePPqKxNq8', metadata={'page': 47, 'source': 'book.pdf'}),\n",
       "  Document(page_content='12 \\n on, providing guidance and support as needed. Additionally, AI -driven tools can \\nautomate and streamline certain aspects of teaching, such as grading and content \\ncreation, freeing up teachers\\' time to focus on engaging and inspiring their \\nstudents. However,  the full potential of AI in education may be limited by \\nfactors such as cost, access, and privacy concerns.  \\nsources = [s.node.get_text() for s in response .source_nodes ] \\nprint(sources[0][0:11]) \\n47Education  \\n \\nThe beauty of this approach is that is simply stores the embeddings into json files. You can take a look at \\nthe storage folder created that maps documents hash to an embedding.  \\nBut this simple text file approach doesn’t scale so well when it comes to storing large document bases. \\nFor this, let’s look into vector databases.  \\n4.2.4.  Vector databases  \\nA vector database is a data store that stores data as high -dimensional vectors, which are mathematical \\nrepresentations of attributes or features.  Some examples of vector databases include: Chroma, \\nPinecone, Weaviate, Faiss, Qdrant, MongoDB  \\nLet’s start with Chroma, that arguably provides the lowest learning curve to set up and use a vector \\ndatabase with semantic search19. Pip install it, discover the basic commands and call it from LangChain.  \\npip install -U langchain langchain -openai pypdf chromadb  \\n \\nimport chromadb  \\n# client = chromadb.HttpClient()  \\nclient = chromadb .PersistentClient () \\ncollection  = client.create_collection (\"sample_collection\" ) \\n \\n# Add docs to the collection. Can also update and delete. Row -based API coming \\nsoon! \\ncollection .add( \\n    documents =[\"This is document1\" , \"This is document2\" ], # we embed for you, \\nor bring your own  \\n    metadatas =[{\"source\" : \"notion\" }, {\"source\" : \"google-docs\"}], # filter on \\narbitrary metadata!  \\n    ids=[\"doc1\", \"doc2\"], # must be unique for each doc  \\n) \\n \\nresults = collection .query( \\n \\n19 Getting Started with ChromaDB  - Lowest Learning Curve Vector Database & Semantic Search  \\nhttps://www.youtube.com/watch?v=QSW2L8dkaZk', metadata={'page': 44, 'source': 'book.pdf'}),\n",
       "  Document(page_content='6 \\n All those limitations motivate the need for another class of search, called vector search.  \\n4.2.2.  Vector search  \\nNow, let\\'s look  into the concept of vector search, a technique for information retrieval that leverages a \\nnumeric representation of text (as vector s) to find semantically similar documents or passages.  \\n- Embeddings: Vector representation of text  \\nVector embeddings6 capture the semantic meaning of text by mapping words, sentences, or documents \\ninto high -dimensional vector spaces. Similar items in this space are close to each other, while dissimilar \\nitems are far apart. This property makes vector embeddings ideal for tasks like search and \\nrecommendation.  \\n \\n- Different ways to break down text into numbers  \\nThis conversion from text to vector can be processed in several ways. A simple approach is to look at \\neach letter as a number. Another approach is words -level embeddings, like Word2Vec7, developed by \\nGoogle . It uses shallow neural networks to produce word embeddings. It comes in two flavors: \\nContinuous Bag -of-Words (CBOW) and Skip -Gram, each capturing different word relationships.  \\n- Example of embedding service  \\nLet’s take a look at an example with the OpenAI’s text embeddings8, on the fi rst paragraph of chapter 1 \\nof A Tale of Two Cities by Charles Dickens9 \\nparagraph  = \"\"\" \\nIt was the best of times, it was the worst of times, it was the age of  \\nwisdom, it was the age of foolishness, it was the epoch of belief, it  \\nwas the epoch of incredulity, it was the season of Light, it was the  \\nseason of Darkness, it was the spring of hope, it was the winter of  \\ndespair, we had everything before us, we had nothing before us, we were  \\nall going direct to Heaven, we were all going direct the other way --in \\nshort, the period was so far like the present period, that some of its  \\n \\n6 Vector Emb eddings: https://www.pinecone.io/learn/vector -embeddings/  - \\nhttps://www.pinecone.io/learn/series/nlp/dense -vector -embeddings -nlp/  \\n7 Word2Vec: https://www.tensorflow.org/text/tutorials/word2vec   \\n8 Open AI’s text embeddings: https://platform.openai.com/docs/guides/embeddings   \\n9 A Tale of Two Cities by Charles Dickens : https://www.gutenberg.org/ebooks/98', metadata={'page': 38, 'source': 'book.pdf'})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the vector databases mentioned in the book?\"\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "# create a chain to answer questions \n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=chat, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "result = qa.invoke({\"query\": query})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
